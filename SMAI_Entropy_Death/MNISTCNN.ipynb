{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "speaking-finder",
   "metadata": {},
   "source": [
    "<h1>CNN MNIST</h1>\n",
    "\n",
    "\n",
    "<h1>Importing required modules</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sharing-indication",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attempted-outreach",
   "metadata": {},
   "source": [
    "<h1>Loading Data</h1>\n",
    "<br/>\n",
    "<p>Loading MNIST data </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "married-volunteer",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batchsize = 100\n",
    "test_batchsize = 100\n",
    "resized_img_size = 28\n",
    "transform = torchvision.transforms.Compose([torchvision.transforms.Resize(size=(resized_img_size, resized_img_size)),\n",
    "                               torchvision.transforms.ToTensor()\n",
    "                             ])\n",
    "train_data = torchvision.datasets.MNIST(root='data', train=True,\n",
    "                                   download=True, transform=transform) \n",
    "test_data = torchvision.datasets.MNIST(root='data', train=False,\n",
    "                                  download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_data,batch_size=train_batchsize,\n",
    "                                          shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data,batch_size=test_batchsize,\n",
    "                                         shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exposed-delta",
   "metadata": {},
   "source": [
    "<h1>Visualize Data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "spiritual-anthony",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc2598d6ac0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_data[100][0][0],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bibliographic-official",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,3,(5,5),padding = \"same\")\n",
    "        self.pool1 = nn.MaxPool2d((3,3),stride=2)\n",
    "        self.conv2 = nn.Conv2d(3,7,(5,5),padding=\"same\")\n",
    "        self.pool2 = nn.MaxPool2d((3,3),stride=2)\n",
    "        self.conv3 = nn.Conv2d(7,9,(5,5),padding=\"same\")\n",
    "        self.pool3 = nn.MaxPool2d((3,3),stride=2)\n",
    "        self.linearlayer = nn.Linear(144,256)\n",
    "        self.linearlayer2 = nn.Linear(256,10)\n",
    "    def forward(self,X):\n",
    "        X = self.pool1(F.relu(self.conv1(X)))\n",
    "        X = self.pool2(F.relu(self.conv2(X)))\n",
    "        X = self.pool3(F.relu(self.conv3(X)))\n",
    "        X = X.view(-1,81) #Flatten\n",
    "        #X = F.relu(self.linearlayer(X))\n",
    "        #X = self.linearlayer2(X)\n",
    "        return X\n",
    "model = Net()\n",
    "#print(train_loader)\n",
    "#print(model([train_data[0][0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "higher-scotland",
   "metadata": {},
   "source": [
    "<h1>CNN model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "vulnerable-calcium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer :  Adam \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 1.993826\n",
      "Epoch: 2 \tTraining Loss: 1.304850\n",
      "Epoch: 3 \tTraining Loss: 1.181985\n",
      "Epoch: 4 \tTraining Loss: 1.105595\n",
      "Epoch: 5 \tTraining Loss: 1.036937\n",
      "Epoch: 6 \tTraining Loss: 1.008230\n",
      "Epoch: 7 \tTraining Loss: 0.985504\n",
      "Epoch: 8 \tTraining Loss: 0.962163\n",
      "Epoch: 9 \tTraining Loss: 0.953557\n",
      "Epoch: 10 \tTraining Loss: 0.938812\n",
      "Epoch: 11 \tTraining Loss: 0.926842\n",
      "Epoch: 12 \tTraining Loss: 0.927297\n",
      "Epoch: 13 \tTraining Loss: 0.907694\n",
      "Epoch: 14 \tTraining Loss: 0.908596\n",
      "Epoch: 15 \tTraining Loss: 0.894461\n",
      "\n",
      "-----------------------------------------\n",
      "\n",
      "Optimizer :  RMSprop \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 2.226989\n",
      "Epoch: 2 \tTraining Loss: 1.741132\n",
      "Epoch: 3 \tTraining Loss: 1.641440\n",
      "Epoch: 4 \tTraining Loss: 1.587898\n",
      "Epoch: 5 \tTraining Loss: 1.551992\n",
      "Epoch: 6 \tTraining Loss: 1.519631\n",
      "Epoch: 7 \tTraining Loss: 1.491073\n",
      "Epoch: 8 \tTraining Loss: 1.460521\n",
      "Epoch: 9 \tTraining Loss: 1.448956\n",
      "Epoch: 10 \tTraining Loss: 1.438098\n",
      "Epoch: 11 \tTraining Loss: 1.424818\n",
      "Epoch: 12 \tTraining Loss: 1.420907\n",
      "Epoch: 13 \tTraining Loss: 1.413265\n",
      "Epoch: 14 \tTraining Loss: 1.406243\n",
      "Epoch: 15 \tTraining Loss: 1.403284\n",
      "\n",
      "-----------------------------------------\n",
      "\n",
      "Optimizer :  SGD \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 2.825060\n",
      "Epoch: 2 \tTraining Loss: 2.485173\n",
      "Epoch: 3 \tTraining Loss: 2.243648\n",
      "Epoch: 4 \tTraining Loss: 2.064395\n",
      "Epoch: 5 \tTraining Loss: 1.933864\n",
      "Epoch: 6 \tTraining Loss: 1.842358\n",
      "Epoch: 7 \tTraining Loss: 1.787283\n",
      "Epoch: 8 \tTraining Loss: 1.740927\n",
      "Epoch: 9 \tTraining Loss: 1.707393\n",
      "Epoch: 10 \tTraining Loss: 1.677203\n",
      "Epoch: 11 \tTraining Loss: 1.398777\n",
      "Epoch: 12 \tTraining Loss: 1.143569\n",
      "Epoch: 13 \tTraining Loss: 1.046011\n",
      "Epoch: 14 \tTraining Loss: 0.986780\n",
      "Epoch: 15 \tTraining Loss: 0.930893\n",
      "\n",
      "-----------------------------------------\n",
      "\n",
      "Optimizer :  Adadelta \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 4.001870\n",
      "Epoch: 2 \tTraining Loss: 2.769197\n",
      "Epoch: 3 \tTraining Loss: 2.710272\n",
      "Epoch: 4 \tTraining Loss: 2.670048\n",
      "Epoch: 5 \tTraining Loss: 2.635135\n",
      "Epoch: 6 \tTraining Loss: 2.603571\n",
      "Epoch: 7 \tTraining Loss: 2.493524\n",
      "Epoch: 8 \tTraining Loss: 2.234223\n",
      "Epoch: 9 \tTraining Loss: 2.139577\n",
      "Epoch: 10 \tTraining Loss: 2.077479\n",
      "Epoch: 11 \tTraining Loss: 2.030576\n",
      "Epoch: 12 \tTraining Loss: 1.991069\n",
      "Epoch: 13 \tTraining Loss: 1.955146\n",
      "Epoch: 14 \tTraining Loss: 1.920715\n",
      "Epoch: 15 \tTraining Loss: 1.886756\n",
      "\n",
      "-----------------------------------------\n",
      "\n",
      "Optimizer :  Adam_scratch \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 2.129391\n",
      "Epoch: 2 \tTraining Loss: 1.564656\n",
      "Epoch: 3 \tTraining Loss: 1.459256\n",
      "Epoch: 4 \tTraining Loss: 1.419334\n",
      "Epoch: 5 \tTraining Loss: 1.388011\n",
      "Epoch: 6 \tTraining Loss: 1.361014\n",
      "Epoch: 7 \tTraining Loss: 1.343303\n",
      "Epoch: 8 \tTraining Loss: 1.326968\n",
      "Epoch: 9 \tTraining Loss: 1.319333\n",
      "Epoch: 10 \tTraining Loss: 1.306456\n",
      "Epoch: 11 \tTraining Loss: 1.299722\n",
      "Epoch: 12 \tTraining Loss: 1.293541\n",
      "Epoch: 13 \tTraining Loss: 1.287421\n",
      "Epoch: 14 \tTraining Loss: 1.282289\n",
      "Epoch: 15 \tTraining Loss: 1.277093\n",
      "\n",
      "-----------------------------------------\n",
      "\n",
      "{'Adam': [1.9938259845097859, 1.304850440343221, 1.1819853694915772, 1.1055946435928345, 1.0369367853482565, 1.0082296516100566, 0.9855040768623352, 0.9621631861686707, 0.9535571797370911, 0.9388124787648519, 0.9268418116251628, 0.9272973799069723, 0.9076938961346944, 0.9085960209210714, 0.894460534922282], 'RMSprop': [2.22698881632487, 1.7411317213058473, 1.6414403359095255, 1.587897683461507, 1.5519921988805134, 1.5196309396743775, 1.4910730688095093, 1.4605207344055176, 1.4489556771914165, 1.4380975867589314, 1.4248182579040527, 1.420907063102722, 1.4132654843648276, 1.406242997678121, 1.4032843456904094], 'SGD': [2.825059874979655, 2.485172643915812, 2.2436482465108236, 2.0643952215830486, 1.9338638357162476, 1.8423583432515462, 1.787283243560791, 1.7409267008463543, 1.7073929646809896, 1.677203392982483, 1.3987771694819133, 1.1435690337498983, 1.046010652478536, 0.9867796923319498, 0.9308925776163737], 'Adadelta': [4.001869629796346, 2.76919654490153, 2.7102716495513914, 2.6700483216603597, 2.6351346378326417, 2.6035712340037027, 2.4935236844380695, 2.2342230086008708, 2.139577372423808, 2.077479447046916, 2.0305763235727947, 1.9910687053044638, 1.955146174367269, 1.9207152201970419, 1.8867562135696412], 'Adam_scratch': [2.1293914613723754, 1.5646556992212932, 1.4592559750239054, 1.4193340425491332, 1.3880109270095826, 1.361013988049825, 1.3433031124750774, 1.326967932955424, 1.3193333798726399, 1.3064560904820761, 1.29972188650767, 1.2935408226648966, 1.2874211533228557, 1.2822891019821168, 1.2770929779052735]}\n"
     ]
    }
   ],
   "source": [
    "from ADAM import ADAM\n",
    "trainingLoss = {}\n",
    "# Fixed seed for random weight initialization (to keep the weights same for all\n",
    "# the models)\n",
    "seed = 11 \n",
    "#torch.manual_seed(3)\n",
    "def trainDifOptimizer(optmzr):\n",
    "    torch.manual_seed(seed)\n",
    "    model = Net()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = None\n",
    "    if optmzr=='Adam_scratch':\n",
    "      optimizer = ADAM(model.parameters(), lr=0.01) # lr=0.001 -> standard\n",
    "    else:\n",
    "      optimizer = getattr(torch.optim, optmzr)(model.parameters(), lr=0.01)\n",
    "    \n",
    "    n_epochs = 15  # suggest training between 20-50 epochs\n",
    "\n",
    "    model.train()  # prep model for training\n",
    "    trainLossForOptimizer = []\n",
    "    print(\"Optimizer : \", optmzr, \"\\n\")\n",
    "    for epoch in range(n_epochs):\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for data, target in train_loader:\n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            # calculate the loss\n",
    "            loss = criterion(output, target)\n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "            # update running training loss\n",
    "            train_loss += loss.item()*data.size(0)\n",
    "\n",
    "        # print training statistics\n",
    "        # calculate average loss over an epoch\n",
    "        train_loss = train_loss/len(train_loader.dataset)\n",
    "        trainLossForOptimizer.append(train_loss)\n",
    "        \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f}'.format(\n",
    "            epoch+1,\n",
    "            train_loss\n",
    "        ))\n",
    "    torch.save(model, 'saved_models/'+optmzr+'_cnn_model')\n",
    "    trainingLoss[optmzr] = trainLossForOptimizer\n",
    "    print(\"\\n-----------------------------------------\\n\")\n",
    "\n",
    "optimizersLst = ['Adam', 'RMSprop','SGD','Adadelta','Adam_scratch']\n",
    "\n",
    "for optmzr in optimizersLst:\n",
    "    trainDifOptimizer(optmzr)\n",
    "print(trainingLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sixth-newark",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainingLoss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-83902ff75012>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training Loss\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# add Y-axis label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CNN on MNIST with different optimizers\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# add title\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainingLoss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainingLoss' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "Xval = np.arange(1, 16,1)\n",
    "\n",
    "plt.xlabel(\"Epoch\")  # add X-axis label\n",
    "plt.ylabel(\"Training Loss\")  # add Y-axis label\n",
    "plt.title(\"CNN on MNIST with different optimizers\")  # add title\n",
    "for key, value in trainingLoss.items():\n",
    "    plt.plot(Xval, value, label=key)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-accused",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
